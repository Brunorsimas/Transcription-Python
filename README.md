# Transcription-Python

Assistente de voz multi-idiomas desenvolvido em Python que combina tecnologias de reconhecimento de fala, processamento de linguagem natural e sÃ­ntese de voz.

## ğŸ¯ Funcionalidades

- **GravaÃ§Ã£o de Ãudio**: Captura de voz do usuÃ¡rio atravÃ©s do navegador
- **TranscriÃ§Ã£o com Whisper**: Reconhecimento de fala usando OpenAI Whisper
- **Processamento com Gemini**: GeraÃ§Ã£o de respostas usando Google Gemini 2.5 Flash
- **SÃ­ntese de Voz**: ConversÃ£o de texto em fala com gTTS
- **Suporte Multi-idiomas**: ConfigurÃ¡vel para diferentes idiomas

## ğŸ› ï¸ Tecnologias Utilizadas

- **OpenAI Whisper**: TranscriÃ§Ã£o de Ã¡udio para texto
- **Google Gemini 2.5 Flash**: Processamento de linguagem natural
- **gTTS (Google Text-to-Speech)**: SÃ­ntese de voz
- **Python**: Linguagem principal
- **JavaScript**: GravaÃ§Ã£o de Ã¡udio no navegador

## ğŸ“‹ PrÃ©-requisitos

- Python 3.7+
- Conta Google Cloud com API Gemini ativada
- Navegador web com suporte a MediaStream Recording API

## ğŸš€ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/Brunorsimas/Transcription-Python.git
cd Transcription-Python
```

2. Instale as dependÃªncias:
```bash
pip install openai-whisper gtts google-generativeai
```

## âš™ï¸ ConfiguraÃ§Ã£o

1. Obtenha sua API Key do Google Gemini:
   - Acesse [Google AI Studio](https://makersuite.google.com/app/apikey)
   - Crie uma nova API Key
   - Copie a chave gerada

2. Configure a API Key no cÃ³digo:
   - Substitua `'AIzaSyCqeiQdU5dT5dSJUNjE92N9AqDit98_oMU'` pela sua chave
   - Ou defina como variÃ¡vel de ambiente: `export GOOGLE_API_KEY=sua_chave`

## ğŸ“– Como Usar

O projeto foi originalmente desenvolvido para Google Colab e consiste em um fluxo completo:

1. **GravaÃ§Ã£o**: O sistema grava Ã¡udio do usuÃ¡rio atravÃ©s do navegador
2. **TranscriÃ§Ã£o**: Whisper converte o Ã¡udio em texto
3. **Processamento**: Gemini analisa o texto e gera uma resposta
4. **SÃ­ntese**: gTTS converte a resposta em Ã¡udio

### Para uso local:

Modifique o arquivo para adaptar Ã s necessidades locais, removendo dependÃªncias do Google Colab e ajustando os caminhos dos arquivos.

## ğŸ“ Estrutura do Projeto

```
Transcription-Python/
â”œâ”€â”€ cÃ³pia_de_assistente_de_voz_multi_idiomas_com_whisper_e_chatgpt.py
â””â”€â”€ README.md
```

## ğŸ”§ VariÃ¡veis ConfigurÃ¡veis

- `language`: Idioma para transcriÃ§Ã£o e sÃ­ntese (padrÃ£o: 'pt')
- `record_file`: Caminho do arquivo de Ã¡udio de entrada
- `response_audio`: Caminho do arquivo de Ã¡udio de saÃ­da

## ğŸ“ Notas

- O cÃ³digo atual contÃ©m referÃªncias ao Google Colab que precisam ser adaptadas para uso local
- A gravaÃ§Ã£o de Ã¡udio utiliza JavaScript e funciona melhor em ambiente de notebook
- O modelo Whisper "small" oferece bom equilÃ­brio entre velocidade e precisÃ£o

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues ou pull requests.

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob licenÃ§a MIT.