# -*- coding: utf-8 -*-
"""C칩pia de Assistente de Voz Multi-Idiomas Com Whisper e ChatGPT

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uqEd2aecynkGPzBQAKl7OgtoBRPbxq2i
"""

language = 'pt'

"""# 1. Grava칞칚o de 츼udio Com Python (e Uma Pitada de JavaScript) 游꿗"""

# Refer칡ncia: https://gist.github.com/korakot/c21c3476c024ad6d56d5f48b0bca92be

from IPython.display import Audio, display, Javascript
from google.colab import output
from base64 import b64decode

# C칩digo JavaScript para gravar 치udio do usu치rio usando a "MediaStream Recording API"
RECORD = """
const sleep  = time => new Promise(resolve => setTimeout(resolve, time))
const b2text = blob => new Promise(resolve => {
  const reader = new FileReader()
  reader.onloadend = e => resolve(e.srcElement.result)
  reader.readAsDataURL(blob)
})
var record = time => new Promise(async resolve => {
  stream = await navigator.mediaDevices.getUserMedia({ audio: true })
  recorder = new MediaRecorder(stream)
  chunks = []
  recorder.ondataavailable = e => chunks.push(e.data)
  recorder.start()
  await sleep(time)
  recorder.onstop = async ()=>{
    blob = new Blob(chunks)
    text = await b2text(blob)
    resolve(text)
  }
  recorder.stop()
})
"""

def record(sec=5):
  # Executa o c칩digo JavaScript para gravar o 치udio
  display(Javascript(RECORD))
  # Recebe o 치udio gravado como resultado do JavaScript
  js_result = output.eval_js('record(%s)' % (sec * 1000))
   # Decodifica o 치udio em base64
  audio = b64decode(js_result.split(',')[1])
  # Salva o 치udio em um arquivo
  file_name = 'request_audio.wav'
  with open(file_name, 'wb') as f:
    f.write(audio)
  # Retorna o caminho do arquivo de 치udio (pasta padr칚o do Google Colab)
  return f'/content/{file_name}'

# Usa o arquivo de 치udio fornecido pelo usu치rio.
record_file = '/content/file_name.mp3'
print(f'Ouvindo o audio... {record_file}')

# Exibe o 치udio gravado
display(Audio(record_file, autoplay=False))

from google.colab import drive
drive.mount('/content/drive')

"""# 2. Reconhecimento de Fala com Whisper (Gemini) 游"""

# comando para instalar o whisper: !pip install git+https://github.com/openai/whisper.git -q

import whisper

language = 'pt'
# Selecione o modelo do Whisper que melhor atenda 맙 suas necessidades:
# https://github.com/openai/whisper#available-models-and-languages
model = whisper.load_model("small")

# Transcreve o audio gravado anteriormente.
print(f'Transcrevendo o 치udio do arquivo: {record_file}')
result = model.transcribe(record_file, fp16=False, language=language)
transcription = result["text"]
print(transcription)

"""# 3. Integra칞칚o com a API do Gemini 游눫"""

# comando para instalar o openai: !pip install openai

import os

# Documenta칞칚o Oficial da API OpenAI: https://platform.openai.com/docs/api-reference/introduction
# Informa칞칫es sobre o Per칤odo Gratuito: https://help.openai.com/en/articles/4936830

# Para gerar uma API Key:
# 1. Crie uma conta na OpenAI
# 2. Acesse a se칞칚o "API Keys"
# 3. Clique em "Create API Key"
# Link direto: https://platform.openai.com/account/api-keys

# Substitua o texto "TODO" por sua API Key da OpenAI, ela ser치 salva como uma vari치vel de ambiente.
os.environ['GEMINI_API_KEY'] = 'AIzaSyCqeiQdU5dT5dSJUNjE92N9AqDit98_oMU'

import gemini_api_key
from gemini_api_key import GEMINI_API_KEY

# Configura a chave de API da OpenAI usando a vari치vel de ambiente 'OPENAI_API_KEY'
# openai.api_key = os.environ.get('OPENAI_API_KEY') # This line is no longer needed with the new client

# Instancia o cliente da OpenAI
client = GEMINI_APEI_KEY(api_key=os.environ.get('OPENAI_API_KEY'))

# Envia uma requisi칞칚o  API do ChatCompletion usando o modelo GPT-3.5 Turbo
# Lembrando que, a vari치vel 'transcription' cont칠m a transcri칞칚o do nosso 치udio.
response = client.chat.completions.create(
    model="Gemini 2.5",
    messages=[ { "role": "user", "content": transcription } ]
)

# Obt칠m a resposta gerada pelo ChatGPT
chatgpt_response = response.choices[0].message.content
print(chatgpt_response)

"""# 4. Sintetizando a Resposta do Gemini Como Voz (gTTS) 游댉"""

# comando para instalar o gTTS: !pip install gTTS

from gtts import  gTTS

# Cria um objeto gTTS com a resposta gerada pelo ChatGPT e a l칤ngua que ser치 sintetizada em voz (vari치vel "language").
gtts_object = gTTS(text=chatgpt_response, lang=language, slow=False)

# Salva o 치udio da resposta no arquivo especificado (pasta padr칚o do Google Colab)
response_audio = "/content/response_audio.wav"
gtts_object.save(response_audio)

# Reproduz o 치udio da resposta salvo no arquivo
display(Audio(response_audio, autoplay=True))

import google.generativeai as genai
from gtts import gTTS
from IPython.display import Audio, display
import os

# 3. Define as vari치veis language e record_file
language = 'pt'
record_file = '/content/file_name.mp3'

# 4. Define a vari치vel gemini_api_key
gemini_api_key = 'AIzaSyCqeiQdU5dT5dSJUNjE92N9AqDit98_oMU'

# 5. Configure a vari치vel de ambiente GOOGLE_API_KEY
os.environ['GOOGLE_API_KEY'] = gemini_api_key

# 6. Configure o genai com a chave da API
genai.configure(api_key=gemini_api_key)

# 7. Define a fun칞칚o upload_audio
def upload_audio(file_path, mime_type):
    uploaded_file = genai.upload_file(
        file_path,
        display_name=file_path.split('/')[-1],
        mime_type=mime_type
    )
    return uploaded_file

# 8. Chame a fun칞칚o upload_audio
#print(f'Carregando o arquivo de 치udio para o Gemini: {record_file}')
uploaded_audio_file = upload_audio(record_file, 'audio/mpeg')
#print(f'Arquivo de 치udio carregado: {uploaded_audio_file.name}')

# 9. Inicialize o modelo Gemini para transcri칞칚o e conte칰do
model = genai.GenerativeModel('gemini-2.5-flash')

# 10. Transcreva o 치udio de entrada
#print(f'Transcrevendo o 치udio de entrada com o modelo Gemini...')
response_transcription = model.generate_content([
    "Transcreva este 치udio:",
    uploaded_audio_file
])
transcription = response_transcription.text
#print("Transcri칞칚o do 치udio de entrada:")
#print(transcription)

# 11. Gere a resposta do Gemini usando a transcri칞칚o
#print(f'\nGerando resposta com o modelo Gemini para a transcri칞칚o: {transcription}')
response_chat = model.generate_content(transcription)
chatgpt_response = response_chat.text
print(chatgpt_response)

# 12. Crie um objeto gTTS com a resposta do Gemini
gtts_object = gTTS(text=chatgpt_response, lang=language, slow=False)

# 13. Salve o 치udio gerado pelo gTTS
response_audio = "/content/response_audio.wav"
gtts_object.save(response_audio)

# A reprodu칞칚o do 치udio foi removida conforme sua solicita칞칚o.
# print("츼udio da resposta do Gemini sintetizado e reproduzido.")

# 15. Transcreva o 치udio gerado pelo gTTS de volta para texto usando o Gemini
#print(f'\nTranscrevendo o 치udio da resposta do Gemini para verifica칞칚o...')
uploaded_response_audio_file = upload_audio(response_audio, 'audio/wav') # Assuming gTTS saves as WAV
response_retranscription = model.generate_content([
    "Transcreva este 치udio:",
    uploaded_response_audio_file
])
retranscription = response_retranscription.text
print("Resposta do Gemini:")
print(retranscription)